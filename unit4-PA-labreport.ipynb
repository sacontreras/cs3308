{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Inverted Index\n",
    "- Create the Inverted Index\n",
    "- Store it in a SQLite Database\n",
    "- Compute $idf_t$ of each term in the Vocabulary\n",
    "- Compute the corresponding $tfidf$ of each term/document combination\n",
    "- Verify the computations were done correctly using the `scikit-learn` API library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unit4.indexer as indexer\n",
    "import unit4.indexer_storage as indexer_storage\n",
    "from unit4.indexer_storage import SQLiteInvertedIndexStorage\n",
    "from common.sqlite_utils import SQLiteDBManager\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from IPython.core.display import HTML, Markdown\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documents in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CACM-0001.html CACM-0115.html CACM-0229.html CACM-0343.html CACM-0457.html\n",
      "CACM-0002.html CACM-0116.html CACM-0230.html CACM-0344.html CACM-0458.html\n",
      "CACM-0003.html CACM-0117.html CACM-0231.html CACM-0345.html CACM-0459.html\n",
      "CACM-0004.html CACM-0118.html CACM-0232.html CACM-0346.html CACM-0460.html\n",
      "CACM-0005.html CACM-0119.html CACM-0233.html CACM-0347.html CACM-0461.html\n",
      "CACM-0006.html CACM-0120.html CACM-0234.html CACM-0348.html CACM-0462.html\n",
      "CACM-0007.html CACM-0121.html CACM-0235.html CACM-0349.html CACM-0463.html\n",
      "CACM-0008.html CACM-0122.html CACM-0236.html CACM-0350.html CACM-0464.html\n",
      "CACM-0009.html CACM-0123.html CACM-0237.html CACM-0351.html CACM-0465.html\n",
      "CACM-0010.html CACM-0124.html CACM-0238.html CACM-0352.html CACM-0466.html\n",
      "CACM-0011.html CACM-0125.html CACM-0239.html CACM-0353.html CACM-0467.html\n",
      "CACM-0012.html CACM-0126.html CACM-0240.html CACM-0354.html CACM-0468.html\n",
      "CACM-0013.html CACM-0127.html CACM-0241.html CACM-0355.html CACM-0469.html\n",
      "CACM-0014.html CACM-0128.html CACM-0242.html CACM-0356.html CACM-0470.html\n",
      "CACM-0015.html CACM-0129.html CACM-0243.html CACM-0357.html CACM-0471.html\n",
      "CACM-0016.html CACM-0130.html CACM-0244.html CACM-0358.html CACM-0472.html\n",
      "CACM-0017.html CACM-0131.html CACM-0245.html CACM-0359.html CACM-0473.html\n",
      "CACM-0018.html CACM-0132.html CACM-0246.html CACM-0360.html CACM-0474.html\n",
      "CACM-0019.html CACM-0133.html CACM-0247.html CACM-0361.html CACM-0475.html\n",
      "CACM-0020.html CACM-0134.html CACM-0248.html CACM-0362.html CACM-0476.html\n",
      "CACM-0021.html CACM-0135.html CACM-0249.html CACM-0363.html CACM-0477.html\n",
      "CACM-0022.html CACM-0136.html CACM-0250.html CACM-0364.html CACM-0478.html\n",
      "CACM-0023.html CACM-0137.html CACM-0251.html CACM-0365.html CACM-0479.html\n",
      "CACM-0024.html CACM-0138.html CACM-0252.html CACM-0366.html CACM-0480.html\n",
      "CACM-0025.html CACM-0139.html CACM-0253.html CACM-0367.html CACM-0481.html\n",
      "CACM-0026.html CACM-0140.html CACM-0254.html CACM-0368.html CACM-0482.html\n",
      "CACM-0027.html CACM-0141.html CACM-0255.html CACM-0369.html CACM-0483.html\n",
      "CACM-0028.html CACM-0142.html CACM-0256.html CACM-0370.html CACM-0484.html\n",
      "CACM-0029.html CACM-0143.html CACM-0257.html CACM-0371.html CACM-0485.html\n",
      "CACM-0030.html CACM-0144.html CACM-0258.html CACM-0372.html CACM-0486.html\n",
      "CACM-0031.html CACM-0145.html CACM-0259.html CACM-0373.html CACM-0487.html\n",
      "CACM-0032.html CACM-0146.html CACM-0260.html CACM-0374.html CACM-0488.html\n",
      "CACM-0033.html CACM-0147.html CACM-0261.html CACM-0375.html CACM-0489.html\n",
      "CACM-0034.html CACM-0148.html CACM-0262.html CACM-0376.html CACM-0490.html\n",
      "CACM-0035.html CACM-0149.html CACM-0263.html CACM-0377.html CACM-0491.html\n",
      "CACM-0036.html CACM-0150.html CACM-0264.html CACM-0378.html CACM-0492.html\n",
      "CACM-0037.html CACM-0151.html CACM-0265.html CACM-0379.html CACM-0493.html\n",
      "CACM-0038.html CACM-0152.html CACM-0266.html CACM-0380.html CACM-0494.html\n",
      "CACM-0039.html CACM-0153.html CACM-0267.html CACM-0381.html CACM-0495.html\n",
      "CACM-0040.html CACM-0154.html CACM-0268.html CACM-0382.html CACM-0496.html\n",
      "CACM-0041.html CACM-0155.html CACM-0269.html CACM-0383.html CACM-0497.html\n",
      "CACM-0042.html CACM-0156.html CACM-0270.html CACM-0384.html CACM-0498.html\n",
      "CACM-0043.html CACM-0157.html CACM-0271.html CACM-0385.html CACM-0499.html\n",
      "CACM-0044.html CACM-0158.html CACM-0272.html CACM-0386.html CACM-0500.html\n",
      "CACM-0045.html CACM-0159.html CACM-0273.html CACM-0387.html CACM-0501.html\n",
      "CACM-0046.html CACM-0160.html CACM-0274.html CACM-0388.html CACM-0502.html\n",
      "CACM-0047.html CACM-0161.html CACM-0275.html CACM-0389.html CACM-0503.html\n",
      "CACM-0048.html CACM-0162.html CACM-0276.html CACM-0390.html CACM-0504.html\n",
      "CACM-0049.html CACM-0163.html CACM-0277.html CACM-0391.html CACM-0505.html\n",
      "CACM-0050.html CACM-0164.html CACM-0278.html CACM-0392.html CACM-0506.html\n",
      "CACM-0051.html CACM-0165.html CACM-0279.html CACM-0393.html CACM-0507.html\n",
      "CACM-0052.html CACM-0166.html CACM-0280.html CACM-0394.html CACM-0508.html\n",
      "CACM-0053.html CACM-0167.html CACM-0281.html CACM-0395.html CACM-0509.html\n",
      "CACM-0054.html CACM-0168.html CACM-0282.html CACM-0396.html CACM-0510.html\n",
      "CACM-0055.html CACM-0169.html CACM-0283.html CACM-0397.html CACM-0511.html\n",
      "CACM-0056.html CACM-0170.html CACM-0284.html CACM-0398.html CACM-0512.html\n",
      "CACM-0057.html CACM-0171.html CACM-0285.html CACM-0399.html CACM-0513.html\n",
      "CACM-0058.html CACM-0172.html CACM-0286.html CACM-0400.html CACM-0514.html\n",
      "CACM-0059.html CACM-0173.html CACM-0287.html CACM-0401.html CACM-0515.html\n",
      "CACM-0060.html CACM-0174.html CACM-0288.html CACM-0402.html CACM-0516.html\n",
      "CACM-0061.html CACM-0175.html CACM-0289.html CACM-0403.html CACM-0517.html\n",
      "CACM-0062.html CACM-0176.html CACM-0290.html CACM-0404.html CACM-0518.html\n",
      "CACM-0063.html CACM-0177.html CACM-0291.html CACM-0405.html CACM-0519.html\n",
      "CACM-0064.html CACM-0178.html CACM-0292.html CACM-0406.html CACM-0520.html\n",
      "CACM-0065.html CACM-0179.html CACM-0293.html CACM-0407.html CACM-0521.html\n",
      "CACM-0066.html CACM-0180.html CACM-0294.html CACM-0408.html CACM-0522.html\n",
      "CACM-0067.html CACM-0181.html CACM-0295.html CACM-0409.html CACM-0523.html\n",
      "CACM-0068.html CACM-0182.html CACM-0296.html CACM-0410.html CACM-0524.html\n",
      "CACM-0069.html CACM-0183.html CACM-0297.html CACM-0411.html CACM-0525.html\n",
      "CACM-0070.html CACM-0184.html CACM-0298.html CACM-0412.html CACM-0526.html\n",
      "CACM-0071.html CACM-0185.html CACM-0299.html CACM-0413.html CACM-0527.html\n",
      "CACM-0072.html CACM-0186.html CACM-0300.html CACM-0414.html CACM-0528.html\n",
      "CACM-0073.html CACM-0187.html CACM-0301.html CACM-0415.html CACM-0529.html\n",
      "CACM-0074.html CACM-0188.html CACM-0302.html CACM-0416.html CACM-0530.html\n",
      "CACM-0075.html CACM-0189.html CACM-0303.html CACM-0417.html CACM-0531.html\n",
      "CACM-0076.html CACM-0190.html CACM-0304.html CACM-0418.html CACM-0532.html\n",
      "CACM-0077.html CACM-0191.html CACM-0305.html CACM-0419.html CACM-0533.html\n",
      "CACM-0078.html CACM-0192.html CACM-0306.html CACM-0420.html CACM-0534.html\n",
      "CACM-0079.html CACM-0193.html CACM-0307.html CACM-0421.html CACM-0535.html\n",
      "CACM-0080.html CACM-0194.html CACM-0308.html CACM-0422.html CACM-0536.html\n",
      "CACM-0081.html CACM-0195.html CACM-0309.html CACM-0423.html CACM-0537.html\n",
      "CACM-0082.html CACM-0196.html CACM-0310.html CACM-0424.html CACM-0538.html\n",
      "CACM-0083.html CACM-0197.html CACM-0311.html CACM-0425.html CACM-0539.html\n",
      "CACM-0084.html CACM-0198.html CACM-0312.html CACM-0426.html CACM-0540.html\n",
      "CACM-0085.html CACM-0199.html CACM-0313.html CACM-0427.html CACM-0541.html\n",
      "CACM-0086.html CACM-0200.html CACM-0314.html CACM-0428.html CACM-0542.html\n",
      "CACM-0087.html CACM-0201.html CACM-0315.html CACM-0429.html CACM-0543.html\n",
      "CACM-0088.html CACM-0202.html CACM-0316.html CACM-0430.html CACM-0544.html\n",
      "CACM-0089.html CACM-0203.html CACM-0317.html CACM-0431.html CACM-0545.html\n",
      "CACM-0090.html CACM-0204.html CACM-0318.html CACM-0432.html CACM-0546.html\n",
      "CACM-0091.html CACM-0205.html CACM-0319.html CACM-0433.html CACM-0547.html\n",
      "CACM-0092.html CACM-0206.html CACM-0320.html CACM-0434.html CACM-0548.html\n",
      "CACM-0093.html CACM-0207.html CACM-0321.html CACM-0435.html CACM-0549.html\n",
      "CACM-0094.html CACM-0208.html CACM-0322.html CACM-0436.html CACM-0550.html\n",
      "CACM-0095.html CACM-0209.html CACM-0323.html CACM-0437.html CACM-0551.html\n",
      "CACM-0096.html CACM-0210.html CACM-0324.html CACM-0438.html CACM-0552.html\n",
      "CACM-0097.html CACM-0211.html CACM-0325.html CACM-0439.html CACM-0553.html\n",
      "CACM-0098.html CACM-0212.html CACM-0326.html CACM-0440.html CACM-0554.html\n",
      "CACM-0099.html CACM-0213.html CACM-0327.html CACM-0441.html CACM-0555.html\n",
      "CACM-0100.html CACM-0214.html CACM-0328.html CACM-0442.html CACM-0556.html\n",
      "CACM-0101.html CACM-0215.html CACM-0329.html CACM-0443.html CACM-0557.html\n",
      "CACM-0102.html CACM-0216.html CACM-0330.html CACM-0444.html CACM-0558.html\n",
      "CACM-0103.html CACM-0217.html CACM-0331.html CACM-0445.html CACM-0559.html\n",
      "CACM-0104.html CACM-0218.html CACM-0332.html CACM-0446.html CACM-0560.html\n",
      "CACM-0105.html CACM-0219.html CACM-0333.html CACM-0447.html CACM-0561.html\n",
      "CACM-0106.html CACM-0220.html CACM-0334.html CACM-0448.html CACM-0562.html\n",
      "CACM-0107.html CACM-0221.html CACM-0335.html CACM-0449.html CACM-0563.html\n",
      "CACM-0108.html CACM-0222.html CACM-0336.html CACM-0450.html CACM-0564.html\n",
      "CACM-0109.html CACM-0223.html CACM-0337.html CACM-0451.html CACM-0565.html\n",
      "CACM-0110.html CACM-0224.html CACM-0338.html CACM-0452.html CACM-0566.html\n",
      "CACM-0111.html CACM-0225.html CACM-0339.html CACM-0453.html CACM-0567.html\n",
      "CACM-0112.html CACM-0226.html CACM-0340.html CACM-0454.html CACM-0568.html\n",
      "CACM-0113.html CACM-0227.html CACM-0341.html CACM-0455.html CACM-0569.html\n",
      "CACM-0114.html CACM-0228.html CACM-0342.html CACM-0456.html CACM-0570.html\n"
     ]
    }
   ],
   "source": [
    "!ls ./unit4/cacm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"./unit4\"\n",
    "corpus_dir = root_dir+\"/cacm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time: 14:48\n",
      "Indexing Complete, writing to storage (sqlite database): 14:48\n",
      "Documents 570\n",
      "Terms 2469\n",
      "Tokens 9282\n",
      "End Time: 14:48\n"
     ]
    }
   ],
   "source": [
    "indexer.LocalFileInvertedIndexer(storage=SQLiteInvertedIndexStorage(root_dir=root_dir)).reindex_directory(dirname=corpus_dir, verbose=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_idx_sqldbm = SQLiteDBManager(root_dir+\"/indexer_part2.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocumentName</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DocId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./unit4/cacm/CACM-0270.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./unit4/cacm/CACM-0335.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./unit4/cacm/CACM-0509.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./unit4/cacm/CACM-0159.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>./unit4/cacm/CACM-0227.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>./unit4/cacm/CACM-0526.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>./unit4/cacm/CACM-0208.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>./unit4/cacm/CACM-0434.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>./unit4/cacm/CACM-0064.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>./unit4/cacm/CACM-0121.html</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>570 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      DocumentName\n",
       "DocId                             \n",
       "1      ./unit4/cacm/CACM-0270.html\n",
       "2      ./unit4/cacm/CACM-0335.html\n",
       "3      ./unit4/cacm/CACM-0509.html\n",
       "4      ./unit4/cacm/CACM-0159.html\n",
       "5      ./unit4/cacm/CACM-0227.html\n",
       "...                            ...\n",
       "566    ./unit4/cacm/CACM-0526.html\n",
       "567    ./unit4/cacm/CACM-0208.html\n",
       "568    ./unit4/cacm/CACM-0434.html\n",
       "569    ./unit4/cacm/CACM-0064.html\n",
       "570    ./unit4/cacm/CACM-0121.html\n",
       "\n",
       "[570 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_document_dict = inv_idx_sqldbm.sql_query_to_df(\"\"\"\n",
    "    SELECT \n",
    "        DocId, DocumentName \n",
    "    FROM \n",
    "        DocumentDictionary \n",
    "    ORDER BY \n",
    "        DocId\n",
    "\"\"\").set_index('DocId')\n",
    "df_document_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>N</th>\n",
       "      <th>df_t</th>\n",
       "      <th>idf_t</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TermId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>techniqu</td>\n",
       "      <td>570</td>\n",
       "      <td>30</td>\n",
       "      <td>2.944439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>storag</td>\n",
       "      <td>570</td>\n",
       "      <td>21</td>\n",
       "      <td>3.301114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alloc</td>\n",
       "      <td>570</td>\n",
       "      <td>14</td>\n",
       "      <td>3.706579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>algorithm</td>\n",
       "      <td>570</td>\n",
       "      <td>217</td>\n",
       "      <td>0.965739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cacm</td>\n",
       "      <td>570</td>\n",
       "      <td>570</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>ca600403</td>\n",
       "      <td>570</td>\n",
       "      <td>1</td>\n",
       "      <td>6.345636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>poor</td>\n",
       "      <td>570</td>\n",
       "      <td>1</td>\n",
       "      <td>6.345636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>ca621205</td>\n",
       "      <td>570</td>\n",
       "      <td>1</td>\n",
       "      <td>6.345636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>ca590905</td>\n",
       "      <td>570</td>\n",
       "      <td>1</td>\n",
       "      <td>6.345636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>ca601114</td>\n",
       "      <td>570</td>\n",
       "      <td>1</td>\n",
       "      <td>6.345636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2469 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Term    N  df_t     idf_t\n",
       "TermId                                \n",
       "1        techniqu  570    30  2.944439\n",
       "2          storag  570    21  3.301114\n",
       "3           alloc  570    14  3.706579\n",
       "4       algorithm  570   217  0.965739\n",
       "5            cacm  570   570  0.000000\n",
       "...           ...  ...   ...       ...\n",
       "2465     ca600403  570     1  6.345636\n",
       "2466         poor  570     1  6.345636\n",
       "2467     ca621205  570     1  6.345636\n",
       "2468     ca590905  570     1  6.345636\n",
       "2469     ca601114  570     1  6.345636\n",
       "\n",
       "[2469 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_term_dict = inv_idx_sqldbm.sql_query_to_df(\"\"\"\n",
    "    SELECT \n",
    "        TermId, Term, N, df_t, idf_t \n",
    "    FROM \n",
    "        TermDictionary \n",
    "    ORDER BY \n",
    "        TermId\n",
    "\"\"\").set_index('TermId')\n",
    "df_term_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tf_t_d</th>\n",
       "      <th>idf_t</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TermId</th>\n",
       "      <th>DocId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>2.944439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>2.944439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>8.833317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>2.944439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>2.944439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <th>567</th>\n",
       "      <td>1</td>\n",
       "      <td>6.345636</td>\n",
       "      <td>6.345636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <th>568</th>\n",
       "      <td>1</td>\n",
       "      <td>6.345636</td>\n",
       "      <td>6.345636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <th>568</th>\n",
       "      <td>1</td>\n",
       "      <td>6.345636</td>\n",
       "      <td>6.345636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <th>569</th>\n",
       "      <td>1</td>\n",
       "      <td>6.345636</td>\n",
       "      <td>6.345636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <th>570</th>\n",
       "      <td>1</td>\n",
       "      <td>6.345636</td>\n",
       "      <td>6.345636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8154 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tf_t_d     idf_t     tfidf\n",
       "TermId DocId                            \n",
       "1      1           1  2.944439  2.944439\n",
       "       6           1  2.944439  2.944439\n",
       "       19          3  2.944439  8.833317\n",
       "       26          1  2.944439  2.944439\n",
       "       39          1  2.944439  2.944439\n",
       "...              ...       ...       ...\n",
       "2465   567         1  6.345636  6.345636\n",
       "2466   568         1  6.345636  6.345636\n",
       "2467   568         1  6.345636  6.345636\n",
       "2468   569         1  6.345636  6.345636\n",
       "2469   570         1  6.345636  6.345636\n",
       "\n",
       "[8154 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_posting = inv_idx_sqldbm.sql_query_to_df(\"\"\"\n",
    "    SELECT \n",
    "        TermId, DocId, tf_t_d, idf_t, tfidf \n",
    "    FROM \n",
    "        Posting \n",
    "    ORDER BY \n",
    "        TermId, DocId\n",
    "\"\"\").set_index(['TermId', 'DocId'])\n",
    "df_posting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now the question is: ***was $idf_t$ and consequently $tfidf$ computed correctly?***\n",
    "To answer this question, I will use the tried and tested `scikit-learn` (usually abbreviated `sklearn`) library (\"scikit-learn: machine learning in Python — scikit-learn 0.23.1 documentation\", 2020), used in Data Science and Machine Learning for years now, to compute $idf_t$ and then compare it to my results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><br>\n",
    "    \n",
    "## Verify correctness of $idf_t$ computation using `sklearn`'s `TfidfTransformer` for comparison\n",
    "    \n",
    "`sklearn`'s `TfidfTransformer` (\"sklearn.feature_extraction.text.TfidfTransformer — scikit-learn 0.23.1 documentation\", 2020) takes a word-count vector as input, provided by fitting/transforming the corpus of documents with `sklearn`'s `CountVectorizer` (\"sklearn.feature_extraction.text.CountVectorizer — scikit-learn 0.23.1 documentation\", 2020).\n",
    "    \n",
    "`sklearn`'s `CountVectorizer` takes the vector of documents - i.e. the corpus in vector form - as input.\n",
    "    \n",
    "So, as a preliminary step, the corpus itself needs to be vectorized - i.e. each document literally needs to be loaded as a component of this vector.\n",
    "    \n",
    "Note that this means we load the entire corpus into RAM.  \n",
    "    \n",
    "It is important to understand that in a production environment, this is exactly what we want to avoid doing since a corpus of documents is usually far too large to fit into RAM!  \n",
    "But, the whole point of this exercise is to verify that the computation of $idf_t$ was done correctly.  In other words, this is not something we would do in a production environment.  Once we have proven that this computation was, in fact, done correctly, this will never need to be again.  Think of it as the loose equivalent of a mathematical proof.\n",
    "    \n",
    "I'll re-use some functionality I used in creating the inverted index above.  Namely, I want to do the same preprocessing done in that case.  That functionality is housed within the `InvertedIndexDS` class, in the indexer_ds.py Python source code file.\n",
    "    \n",
    "The functionality below does not actually store the inverted index but it does do the same preprocessing as the above.  It also uses the `__walk_directory__` functionality adapted from our \"reference\" source-code.  The bottom line is that I extract the \"corpus vector\" of preprocessed documents so that `sklearn`'s `CountVectorizer` and `TfidfTransformer` can be used to compare its $idf_t$ computations to mine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeInvertedIndexStorage(indexer_storage.AbstractInvertedIndexStorage):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"\", \"INDEX IS NOT ACTUALLY STORED\")\n",
    "        \n",
    "    def init_storage(self):\n",
    "        # do nothing since nothing will actually be stored\n",
    "        print(f\"Message from {self.__class__.__name__}: Hello there. I promise I will not store anything (and certainly will not overwrite any existing inverted index storage)!\")\n",
    "        return\n",
    "    \n",
    "    def insert_doc_dict(self, doc_path, doc_id):\n",
    "        # do nothing since nothing will actually be stored\n",
    "        return\n",
    "    \n",
    "    def insert_term_dict(self, term, termid, N, df_t, idf_t):\n",
    "        # do nothing since nothing will actually be stored\n",
    "        return\n",
    "    \n",
    "    def insert_posting(self, termid, docid, tf_t_d, idf_t, tfidf):\n",
    "        # do nothing since nothing will actually be stored\n",
    "        return\n",
    "    \n",
    "    def finalize_storage(self):\n",
    "        # do nothing since nothing will actually be stored\n",
    "        return\n",
    "    \n",
    "class CustomLocalFileInvertedIndexer(indexer.LocalFileInvertedIndexer):\n",
    "    def __init__(self, skip_preprocessing=False):\n",
    "        self.skip_preprocessing = skip_preprocessing\n",
    "        self.corpus_vector = []\n",
    "        super().__init__(storage=FakeInvertedIndexStorage())\n",
    "        \n",
    "    # override this from base class; in LocalFileInvertedIndexer this function does nothing with the vector of tokens\n",
    "    #    but of course it does update the inverted index data structure (InvertedIndexDS), which we still want to do\n",
    "    #    but we want to use the vector of tokens after a document is preprocessed and tokenized\n",
    "    def process_local_file(self, file):\n",
    "        # the original version in the baseclass does this:\n",
    "#         for l in file.readlines(): \n",
    "#             self.ds.parse_tokenize(l)\n",
    "\n",
    "        if not self.skip_preprocessing:\n",
    "            # but we want ours to do this (when skip_preprocessing is False):\n",
    "            preprocessed_lines = []\n",
    "            for l in file.readlines(): \n",
    "                preprocessed_lines.append(' '.join(self.ds.parse_tokenize(l)))\n",
    "            self.corpus_vector.append(' '.join(preprocessed_lines)) # add the preprocessed version of the document (as one long string) to the corpus vector\n",
    "        else:\n",
    "            # otherwise, let's leave the document as is (so we can inspect by comparison what our documents actually look like AFTER preprocessing)\n",
    "            self.corpus_vector.append(file.read())\n",
    "    \n",
    "    # also override this so that we can reset corpus_vector when skip_preprocessing is changed without having to reinstantiate a new object\n",
    "    def reindex_directory(self, dirname, verbose=False):\n",
    "        self.corpus_vector = []\n",
    "        return super().reindex_directory(dirname, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message from FakeInvertedIndexStorage: Hello there. I promise I will not store anything (and certainly will not overwrite any existing inverted index storage)!\n",
      "Start Time: 14:48\n",
      "Indexing Complete, writing to storage (INDEX IS NOT ACTUALLY STORED): 14:48\n",
      "*** WARNING!!! Apparently none of the <unit4.indexer_ds.InvertedIndexDS object at 0x7fde0a7c31f0> terms occurs in more than one document out of the entire collection of 570 documents!!! ***\n",
      "Documents 570\n",
      "Terms 0\n",
      "Tokens 0\n",
      "End Time: 14:48\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "count docs: 570"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### For example, the first document BEFORE it is (pre)processed:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<pre>\n",
      "\n",
      "\n",
      "Techniques for Storage Allocation Algorithms \n",
      "\n",
      "CACM October, 1961\n",
      "\n",
      "Kelley Jr., J. E.\n",
      "\n",
      "CA611011 JB March 16, 1978  12:50 PM\n",
      "\n",
      "270\t5\t270\n",
      "270\t5\t270\n",
      "270\t5\t270\n",
      "678\t5\t270\n",
      "270\t6\t270\n",
      "\n",
      "</pre>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "custom_localfile_indexer = CustomLocalFileInvertedIndexer(skip_preprocessing=True)\n",
    "custom_localfile_indexer.reindex_directory(dirname=corpus_dir) # remember that this has \"fake\" storage - i.e. nothing is actually getting stored (so the real inverted index stored in the sqlite db is intact\n",
    "\n",
    "docs_not_preprocessed = custom_localfile_indexer.corpus_vector\n",
    "display(Markdown(f\"count docs: {len(docs_not_preprocessed)}\"))\n",
    "display(Markdown(f\"### For example, the first document BEFORE it is (pre)processed:\"))\n",
    "print(docs_not_preprocessed[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><br><br>\n",
    "\n",
    "Note the scary warning that is output above.  This is entirely expected since no preprocessing (and consequently no tokenization) is done when `CustomLocalFileInvertedIndexer.skip_preprocessing==True`.  The effect is that, of course, as expected, the `InvertedIndexDS` is not updated (aside from updating its `InvertedIndexDS.n_documents` member, it is never touched).  But that is beside the point.\n",
    "\n",
    "The point in showing the above was simply \"bonus material\" to be able to see the \"before\" vs \"after\" effects of preprocessing/tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message from FakeInvertedIndexStorage: Hello there. I promise I will not store anything (and certainly will not overwrite any existing inverted index storage)!\n",
      "Start Time: 14:48\n",
      "Indexing Complete, writing to storage (INDEX IS NOT ACTUALLY STORED): 14:48\n",
      "Documents 570\n",
      "Terms 2469\n",
      "Tokens 9282\n",
      "End Time: 14:48\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "count docs: 570"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### For example, the first document AFTER it is (pre)processed:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    techniqu storag alloc algorithm  cacm octob  kellei  ca611011 march         \n"
     ]
    }
   ],
   "source": [
    "custom_localfile_indexer.skip_preprocessing = False\n",
    "custom_localfile_indexer.reindex_directory(dirname=corpus_dir) # remember that this has \"fake\" storage - i.e. nothing is actually getting stored (so the real inverted index stored in the sqlite db is intact\n",
    "\n",
    "docs_preprocessed = custom_localfile_indexer.corpus_vector\n",
    "display(Markdown(f\"count docs: {len(docs_preprocessed)}\"))\n",
    "display(Markdown(f\"### For example, the first document AFTER it is (pre)processed:\"))\n",
    "print(docs_preprocessed[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><br><br>\n",
    "    \n",
    "Now we can actually move on to the guts of this effort: to validate the computation of $idf_t$ was done correctly by comparing the result from the appropriate `sklearn` classes/APIs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(vocabulary=df_term_dict.Term.values)\n",
    "preprocessed_word_count_vector = cv.fit_transform(docs_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer(use_idf=True, smooth_idf=False, norm=None, sublinear_tf=False)\n",
    "tfidf_mat = tfidf_transformer.fit_transform(preprocessed_word_count_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two things to note from the above (using `TfidfTransformer`), based on the official `sklearn` documentation as well as our textbook:\n",
    "1. *`sklearn.TfidfTransformer` documentation*: \"... the idf is computed as idf(t) = log [ n / df(t) ] + 1 (if smooth_idf=False)\"\n",
    "2. *paraphrased from our textbook*: the formula is $idf_t = log_{10}(\\frac{N}{df_t})$ (note the base here is 10) but the authors go on to say that **the base is irrelevant** (Manning, C., Raghavan, P., & Schütze, H., 2008, p. 118)\n",
    "\n",
    "So... since the goal here is to utilize `TfidTransformer` to confirm that my computation of $idf_t$ was done correctly, one of the two computations needs to be adjusted to be scaled and translated to the other.\n",
    "\n",
    "Thus:\n",
    "1. in my computation of $idf_t$, I use the same base used in `sklearn`'s `TfidfTransformer` $idf_t$ computation, which is base $e$ - i.e. I use $idf_t = log_{e}(\\frac{N}{df_t})$ to match `sklearn`'s `TfidfTransformer`\n",
    "2. since `sklearn`'s `TfidfTransformer` $idf_t$ computation translates $log_{e}(\\frac{N}{df_t})$ by 1 (adds 1), when comparing my computed $idf_t$, I subtract 1 from`sklearn`'s `TfidfTransformer` $idf_t$ computation\n",
    "\n",
    "Finally, **if I have coded this assignment correctly, after adjusting according to the above, the two computations of $idf_t$ be identical for EVERY term**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_idf__inv_idx = pd.DataFrame(\n",
    "    {\n",
    "        'term_id__inv_idx': df_term_dict.reset_index().TermId,\n",
    "        'idf_t__inv_idx': df_term_dict.reset_index().idf_t\n",
    "    }\n",
    ").set_index('term_id__inv_idx')\n",
    "\n",
    "df_idf__skl = pd.DataFrame(\n",
    "    {\n",
    "        'term_id__skl': list(range(1, len(tfidf_transformer.idf_)+1)), \n",
    "        'idf_t__skl': tfidf_transformer.idf_-1  # from skl docs: \"the idf is computed as idf(t) = log [ n / df(t) ] + 1 (if smooth_idf=False)\", SO WE MUST SUBTRACT 1\n",
    "    }\n",
    ").set_index('term_id__skl')\n",
    "\n",
    "df_idf_comparison = pd.concat([df_term_dict[['Term']], df_idf__inv_idx, df_idf__skl], axis=1, join='inner')\n",
    "\n",
    "# add a new column that holds the difference between the two\n",
    "df_idf_comparison['delta'] = np.abs(df_idf_comparison.idf_t__inv_idx - df_idf_comparison.idf_t__skl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>idf_t__inv_idx</th>\n",
       "      <th>idf_t__skl</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>equat</td>\n",
       "      <td>3.167583</td>\n",
       "      <td>3.167583</td>\n",
       "      <td>4.440892e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>ibm</td>\n",
       "      <td>3.455265</td>\n",
       "      <td>3.455265</td>\n",
       "      <td>4.440892e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>digit</td>\n",
       "      <td>3.049799</td>\n",
       "      <td>3.049799</td>\n",
       "      <td>4.440892e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>on</td>\n",
       "      <td>3.167583</td>\n",
       "      <td>3.167583</td>\n",
       "      <td>4.440892e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>data</td>\n",
       "      <td>3.049799</td>\n",
       "      <td>3.049799</td>\n",
       "      <td>4.440892e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>discuss</td>\n",
       "      <td>3.455265</td>\n",
       "      <td>3.455265</td>\n",
       "      <td>4.440892e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>polynomi</td>\n",
       "      <td>3.167583</td>\n",
       "      <td>3.167583</td>\n",
       "      <td>4.440892e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>compil</td>\n",
       "      <td>3.210142</td>\n",
       "      <td>3.210142</td>\n",
       "      <td>4.440892e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>algol</td>\n",
       "      <td>3.049799</td>\n",
       "      <td>3.049799</td>\n",
       "      <td>4.440892e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>januari</td>\n",
       "      <td>3.167583</td>\n",
       "      <td>3.167583</td>\n",
       "      <td>4.440892e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>complex</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>4.440892e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>herndon</td>\n",
       "      <td>3.455265</td>\n",
       "      <td>3.455265</td>\n",
       "      <td>4.440892e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>evalu</td>\n",
       "      <td>3.455265</td>\n",
       "      <td>3.455265</td>\n",
       "      <td>4.440892e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>languag</td>\n",
       "      <td>3.210142</td>\n",
       "      <td>3.210142</td>\n",
       "      <td>4.440892e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>automat</td>\n",
       "      <td>3.455265</td>\n",
       "      <td>3.455265</td>\n",
       "      <td>4.440892e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Term  idf_t__inv_idx  idf_t__skl         delta\n",
       "21      equat        3.167583    3.167583  4.440892e-16\n",
       "81        ibm        3.455265    3.455265  4.440892e-16\n",
       "98      digit        3.049799    3.049799  4.440892e-16\n",
       "135        on        3.167583    3.167583  4.440892e-16\n",
       "191      data        3.049799    3.049799  4.440892e-16\n",
       "217   discuss        3.455265    3.455265  4.440892e-16\n",
       "266  polynomi        3.167583    3.167583  4.440892e-16\n",
       "305    compil        3.210142    3.210142  4.440892e-16\n",
       "432     algol        3.049799    3.049799  4.440892e-16\n",
       "433   januari        3.167583    3.167583  4.440892e-16\n",
       "502   complex        3.401197    3.401197  4.440892e-16\n",
       "539   herndon        3.455265    3.455265  4.440892e-16\n",
       "553     evalu        3.455265    3.455265  4.440892e-16\n",
       "575   languag        3.210142    3.210142  4.440892e-16\n",
       "623   automat        3.455265    3.455265  4.440892e-16"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finally, list rows from the above dataframe where idf_t__inv_idx != idf_t__skl\n",
    "df_difference = df_idf_comparison.query(f\"delta > 0\")\n",
    "df_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are evidently 15 terms out of 2469 from the vocabulary where the computation differs.\n",
    "\n",
    "But look at the difference: that value is a decimal-point followed by 16 zeroes.\n",
    "\n",
    "Explanation: floating-point rounding error has occurred.\n",
    "\n",
    "CONCLUSION: **$idf_t$ was computed correctly**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><br><br>\n",
    "\n",
    "# Conclusion\n",
    "I forgot to mention that this document was produced as a (IPython) Jupyter Notebook. (\"Project Jupyter\", 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn: machine learning in Python — scikit-learn 0.23.1 documentation. (2020). Retrieved from https://scikit-learn.org/stable/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.feature_extraction.text.CountVectorizer — scikit-learn 0.23.1 documentation. (2020). Retrieved from https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.feature_extraction.text.TfidfTransformer — scikit-learn 0.23.1 documentation. (2020). Retrieved from https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manning, C., Raghavan, P., & Schütze, H. (2008). Introduction to Information Retrieval [Ebook]. Cambridge University Press. Retrieved from http://nlp.stanford.edu/IR-book/pdf/irbookprint.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Jupyter. (2020). Retrieved from https://jupyter.org/documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda: learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
